{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data extraction and cleaning\n",
    "# data preprocessing stage\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open csv file\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any duplicated entries\n",
    "data.duplicated(keep='last').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      283726\n",
       "V1        283726\n",
       "V2        283726\n",
       "V3        283726\n",
       "V4        283726\n",
       "V5        283726\n",
       "V6        283726\n",
       "V7        283726\n",
       "V8        283726\n",
       "V9        283726\n",
       "V10       283726\n",
       "V11       283726\n",
       "V12       283726\n",
       "V13       283726\n",
       "V14       283726\n",
       "V15       283726\n",
       "V16       283726\n",
       "V17       283726\n",
       "V18       283726\n",
       "V19       283726\n",
       "V20       283726\n",
       "V21       283726\n",
       "V22       283726\n",
       "V23       283726\n",
       "V24       283726\n",
       "V25       283726\n",
       "V26       283726\n",
       "V27       283726\n",
       "V28       283726\n",
       "Amount    283726\n",
       "Class     283726\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null values?\n",
    "data.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine class totals\n",
    "data['Class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unwanted column\n",
    "data.drop(columns=['Time'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    283253\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detemine total for each class\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale \n",
    "data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate class 0 and 1\n",
    "data_0 = data[data['Class'] == 0]\n",
    "data_1 = data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop label for data_0\n",
    "x_data0 = data_0.drop(columns=['Class'])\n",
    "y_data0 = data_0['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data_0\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train0, x_test0, y_train0, y_test0 = train_test_split(\n",
    "    x_data0, y_data0, test_size=0.10, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274842</th>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.845050</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>-0.798504</td>\n",
       "      <td>0.695579</td>\n",
       "      <td>-0.565116</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>-0.062716</td>\n",
       "      <td>-0.349653</td>\n",
       "      <td>-0.255274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>-0.229609</td>\n",
       "      <td>-0.491374</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.400306</td>\n",
       "      <td>-0.451544</td>\n",
       "      <td>0.143434</td>\n",
       "      <td>0.246293</td>\n",
       "      <td>0.084199</td>\n",
       "      <td>-0.343023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90161</th>\n",
       "      <td>1.205443</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.741620</td>\n",
       "      <td>0.746450</td>\n",
       "      <td>-0.682445</td>\n",
       "      <td>-1.276868</td>\n",
       "      <td>0.136546</td>\n",
       "      <td>-0.284828</td>\n",
       "      <td>-0.106272</td>\n",
       "      <td>-0.092854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043590</td>\n",
       "      <td>-0.208169</td>\n",
       "      <td>-0.589665</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>0.933687</td>\n",
       "      <td>0.168355</td>\n",
       "      <td>0.058053</td>\n",
       "      <td>-0.025197</td>\n",
       "      <td>0.027646</td>\n",
       "      <td>-0.309237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41458</th>\n",
       "      <td>-0.275684</td>\n",
       "      <td>1.112403</td>\n",
       "      <td>0.942716</td>\n",
       "      <td>-0.136235</td>\n",
       "      <td>0.427005</td>\n",
       "      <td>-0.504525</td>\n",
       "      <td>0.686810</td>\n",
       "      <td>-0.014106</td>\n",
       "      <td>-0.322820</td>\n",
       "      <td>-0.506743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130043</td>\n",
       "      <td>-0.321393</td>\n",
       "      <td>-0.851229</td>\n",
       "      <td>-0.121964</td>\n",
       "      <td>-0.509255</td>\n",
       "      <td>-0.052742</td>\n",
       "      <td>0.124297</td>\n",
       "      <td>0.244629</td>\n",
       "      <td>0.089349</td>\n",
       "      <td>-0.346218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154410</th>\n",
       "      <td>1.802716</td>\n",
       "      <td>-0.304729</td>\n",
       "      <td>-2.092921</td>\n",
       "      <td>0.191727</td>\n",
       "      <td>0.553230</td>\n",
       "      <td>-1.079475</td>\n",
       "      <td>0.755031</td>\n",
       "      <td>-0.537489</td>\n",
       "      <td>1.236229</td>\n",
       "      <td>-0.280493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061476</td>\n",
       "      <td>0.078572</td>\n",
       "      <td>0.251564</td>\n",
       "      <td>-0.165849</td>\n",
       "      <td>-0.392507</td>\n",
       "      <td>0.277481</td>\n",
       "      <td>0.121611</td>\n",
       "      <td>-0.135312</td>\n",
       "      <td>-0.068539</td>\n",
       "      <td>0.274831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75020</th>\n",
       "      <td>-2.525869</td>\n",
       "      <td>2.202607</td>\n",
       "      <td>0.633063</td>\n",
       "      <td>0.584094</td>\n",
       "      <td>-0.668050</td>\n",
       "      <td>0.201383</td>\n",
       "      <td>0.207289</td>\n",
       "      <td>0.336436</td>\n",
       "      <td>0.751606</td>\n",
       "      <td>1.596623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166092</td>\n",
       "      <td>-0.191501</td>\n",
       "      <td>-0.238654</td>\n",
       "      <td>-0.115595</td>\n",
       "      <td>-0.024809</td>\n",
       "      <td>-0.158276</td>\n",
       "      <td>-0.669323</td>\n",
       "      <td>-1.506852</td>\n",
       "      <td>-0.739474</td>\n",
       "      <td>-0.217064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "274842  0.032432  0.845050  0.161690 -0.798504  0.695579 -0.565116  0.933765   \n",
       "90161   1.205443  0.289451  0.741620  0.746450 -0.682445 -1.276868  0.136546   \n",
       "41458  -0.275684  1.112403  0.942716 -0.136235  0.427005 -0.504525  0.686810   \n",
       "154410  1.802716 -0.304729 -2.092921  0.191727  0.553230 -1.079475  0.755031   \n",
       "75020  -2.525869  2.202607  0.633063  0.584094 -0.668050  0.201383  0.207289   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "274842 -0.062716 -0.349653 -0.255274  ...  0.013430 -0.229609 -0.491374   \n",
       "90161  -0.284828 -0.106272 -0.092854  ... -0.043590 -0.208169 -0.589665   \n",
       "41458  -0.014106 -0.322820 -0.506743  ...  0.130043 -0.321393 -0.851229   \n",
       "154410 -0.537489  1.236229 -0.280493  ...  0.061476  0.078572  0.251564   \n",
       "75020   0.336436  0.751606  1.596623  ...  0.166092 -0.191501 -0.238654   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "274842  0.001259 -0.400306 -0.451544  0.143434  0.246293  0.084199 -0.343023  \n",
       "90161   0.185183  0.933687  0.168355  0.058053 -0.025197  0.027646 -0.309237  \n",
       "41458  -0.121964 -0.509255 -0.052742  0.124297  0.244629  0.089349 -0.346218  \n",
       "154410 -0.165849 -0.392507  0.277481  0.121611 -0.135312 -0.068539  0.274831  \n",
       "75020  -0.115595 -0.024809 -0.158276 -0.669323 -1.506852 -0.739474 -0.217064  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only 480 xtest0 entries\n",
    "# would concatenate with data_1 to use as test dataset for evaluation\n",
    "data_x00 = x_test0[0:480]\n",
    "data_y00 = y_test0[0:480]\n",
    "\n",
    "data_00 = pd.concat([data_x00, data_y00], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the rest\n",
    "x_test0 = x_test0[481:]\n",
    "y_test0 = y_test0[481:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting eveything as one test dataset\n",
    "# i.e. data_00 and data_1\n",
    "test_data = pd.concat([data_00, data_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data to be used is x_train0 and y_train0\n",
    "# test data to be used for evaluation is test_data\n",
    "\n",
    "# create validation dataset out of training dataset\n",
    "x_train0, x_val0, y_train0, y_val0 = train_test_split(\n",
    "    x_train0, y_train0, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50986"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_val0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101739</th>\n",
       "      <td>-0.801057</td>\n",
       "      <td>-0.385518</td>\n",
       "      <td>2.331103</td>\n",
       "      <td>-1.898797</td>\n",
       "      <td>-0.310785</td>\n",
       "      <td>1.923541</td>\n",
       "      <td>-0.938786</td>\n",
       "      <td>0.772570</td>\n",
       "      <td>0.043424</td>\n",
       "      <td>-0.197686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237779</td>\n",
       "      <td>0.114683</td>\n",
       "      <td>0.669152</td>\n",
       "      <td>-0.562270</td>\n",
       "      <td>-1.662374</td>\n",
       "      <td>0.677568</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.349324</td>\n",
       "      <td>0.100234</td>\n",
       "      <td>-0.295020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>-0.070326</td>\n",
       "      <td>1.012150</td>\n",
       "      <td>1.092273</td>\n",
       "      <td>1.529751</td>\n",
       "      <td>0.073325</td>\n",
       "      <td>-0.670071</td>\n",
       "      <td>0.593813</td>\n",
       "      <td>-0.242106</td>\n",
       "      <td>-0.697905</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106013</td>\n",
       "      <td>0.164612</td>\n",
       "      <td>0.600867</td>\n",
       "      <td>-0.012563</td>\n",
       "      <td>0.422773</td>\n",
       "      <td>-0.317828</td>\n",
       "      <td>-0.197786</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.088495</td>\n",
       "      <td>-0.331482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55169</th>\n",
       "      <td>-10.441746</td>\n",
       "      <td>-11.600544</td>\n",
       "      <td>-2.256248</td>\n",
       "      <td>0.287877</td>\n",
       "      <td>-0.322592</td>\n",
       "      <td>-2.986039</td>\n",
       "      <td>1.618101</td>\n",
       "      <td>0.061414</td>\n",
       "      <td>-0.539134</td>\n",
       "      <td>-2.062997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315181</td>\n",
       "      <td>-0.387002</td>\n",
       "      <td>-0.534209</td>\n",
       "      <td>3.466379</td>\n",
       "      <td>0.835440</td>\n",
       "      <td>1.565253</td>\n",
       "      <td>0.078927</td>\n",
       "      <td>1.465506</td>\n",
       "      <td>-3.515276</td>\n",
       "      <td>1.967649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192848</th>\n",
       "      <td>1.998180</td>\n",
       "      <td>-0.475314</td>\n",
       "      <td>-0.732268</td>\n",
       "      <td>0.096951</td>\n",
       "      <td>-0.054346</td>\n",
       "      <td>0.634635</td>\n",
       "      <td>-0.750737</td>\n",
       "      <td>0.215186</td>\n",
       "      <td>1.207636</td>\n",
       "      <td>-0.013737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124653</td>\n",
       "      <td>0.187839</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>-0.115775</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>-0.213925</td>\n",
       "      <td>0.033365</td>\n",
       "      <td>-0.047041</td>\n",
       "      <td>-0.301450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>-0.487943</td>\n",
       "      <td>0.571487</td>\n",
       "      <td>2.170264</td>\n",
       "      <td>1.787858</td>\n",
       "      <td>-1.172119</td>\n",
       "      <td>0.854935</td>\n",
       "      <td>-1.604364</td>\n",
       "      <td>-2.430118</td>\n",
       "      <td>0.901141</td>\n",
       "      <td>-1.000582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863530</td>\n",
       "      <td>-1.199242</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>-0.318814</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>1.124744</td>\n",
       "      <td>-0.044556</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>0.199837</td>\n",
       "      <td>0.081978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "101739  -0.801057  -0.385518  2.331103 -1.898797 -0.310785  1.923541   \n",
       "133010  -0.070326   1.012150  1.092273  1.529751  0.073325 -0.670071   \n",
       "55169  -10.441746 -11.600544 -2.256248  0.287877 -0.322592 -2.986039   \n",
       "192848   1.998180  -0.475314 -0.732268  0.096951 -0.054346  0.634635   \n",
       "10320   -0.487943   0.571487  2.170264  1.787858 -1.172119  0.854935   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V20       V21  \\\n",
       "101739 -0.938786  0.772570  0.043424 -0.197686  ...  0.237779  0.114683   \n",
       "133010  0.593813 -0.242106 -0.697905  0.216305  ...  0.106013  0.164612   \n",
       "55169   1.618101  0.061414 -0.539134 -2.062997  ... -0.315181 -0.387002   \n",
       "192848 -0.750737  0.215186  1.207636 -0.013737  ... -0.124653  0.187839   \n",
       "10320  -1.604364 -2.430118  0.901141 -1.000582  ...  0.863530 -1.199242   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "101739  0.669152 -0.562270 -1.662374  0.677568  0.007671  0.349324  0.100234   \n",
       "133010  0.600867 -0.012563  0.422773 -0.317828 -0.197786  0.029739  0.088495   \n",
       "55169  -0.534209  3.466379  0.835440  1.565253  0.078927  1.465506 -3.515276   \n",
       "192848  0.737913  0.027689 -0.115775  0.018509 -0.213925  0.033365 -0.047041   \n",
       "10320   0.664000 -0.318814  0.499873  1.124744 -0.044556  0.037318  0.199837   \n",
       "\n",
       "          Amount  \n",
       "101739 -0.295020  \n",
       "133010 -0.331482  \n",
       "55169   1.967649  \n",
       "192848 -0.301450  \n",
       "10320   0.081978  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from dataframe to numpy arrays\n",
    "x_train0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203941, 29)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2\n",
    "# Pytorch dataset\n",
    "# Model creation\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = torch.tensor(x)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __type__(self):\n",
    "        return type(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=100, hidden_dim=128, latent_dim=10):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 8, latent_dim * 2) \n",
    "        )\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 8, hidden_dim // 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim) \n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = x.chunk(2, dim=-1) \n",
    "        return mean, logvar\n",
    "\n",
    "    def reparametrize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mean + std * epsilon \n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_dataset = FraudDataset(x_train0.values)\n",
    "model = VAE(input_dim=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "\n",
    "# loss function\n",
    "def loss_function(x_hat, x, mean, logvar):\n",
    "    recon_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    return recon_loss * kl_loss, recon_loss, kl_loss\n",
    "\n",
    "# optimizer\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1944.7855,           Recon Loss: 1934.0680, KL Loss: 10.7175,           Val Loss: 1976.4682\n",
      "Epoch 2/10, Train Loss: 1944.8016,           Recon Loss: 1934.0841, KL Loss: 10.7175,           Val Loss: 1976.4429\n",
      "Epoch 3/10, Train Loss: 1944.8001,           Recon Loss: 1934.0826, KL Loss: 10.7175,           Val Loss: 1976.4336\n",
      "Epoch 4/10, Train Loss: 1944.7904,           Recon Loss: 1934.0728, KL Loss: 10.7175,           Val Loss: 1976.4601\n",
      "Epoch 5/10, Train Loss: 1944.8078,           Recon Loss: 1934.0902, KL Loss: 10.7175,           Val Loss: 1976.4280\n",
      "Epoch 6/10, Train Loss: 1944.7794,           Recon Loss: 1934.0619, KL Loss: 10.7175,           Val Loss: 1976.4594\n",
      "Epoch 7/10, Train Loss: 1944.7956,           Recon Loss: 1934.0781, KL Loss: 10.7175,           Val Loss: 1976.4189\n",
      "Epoch 8/10, Train Loss: 1944.8099,           Recon Loss: 1934.0924, KL Loss: 10.7175,           Val Loss: 1976.4180\n",
      "Epoch 9/10, Train Loss: 1944.8145,           Recon Loss: 1934.0969, KL Loss: 10.7175,           Val Loss: 1976.4256\n",
      "Epoch 10/10, Train Loss: 1944.7877,           Recon Loss: 1934.0701, KL Loss: 10.7175,           Val Loss: 1976.3931\n"
     ]
    }
   ],
   "source": [
    "# Phase 3 \n",
    "# training phase\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(FraudDataset(x_train0.values), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(FraudDataset(x_val0.values), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, recon_loss, kl_loss = 0, 0, 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device, dtype=torch.float)\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        x_hat, mean, logvar = model(batch)\n",
    "        loss, recon, kl = loss_function(x_hat, batch, mean, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        recon_loss += recon.item()\n",
    "        kl_loss += kl.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device, dtype=torch.float)\n",
    "            x_hat, mean, logvar = model(batch)\n",
    "            loss, _, _ = loss_function(x_hat, batch, mean, logvar)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \\\n",
    "          Recon Loss: {recon_loss/len(train_loader):.4f}, KL Loss: {kl_loss/len(train_loader):.4f}, \\\n",
    "          Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
