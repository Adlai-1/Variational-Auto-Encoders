{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries...\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"./archive/creditcard.csv\").astype('float32')\n",
    "\n",
    "# preprocess Data\n",
    "Data = Data.drop(['Time'], axis=1)\n",
    "Data['Amount'] = StandardScaler().fit_transform(Data['Amount'].values.reshape(-1,1))\n",
    "\n",
    "fraud = Data[Data['Class'] == 1]\n",
    "nonFraud = Data[Data['Class'] == 0]\n",
    "\n",
    "# seperate nonfraud data \n",
    "trainData, testData = train_test_split(nonFraud, train_size=0.9)\n",
    "\n",
    "# add fraud data to testData\n",
    "testData = pd.concat([fraud, testData])\n",
    "\n",
    "# final preprocessing\n",
    "trainData = trainData.drop(['Class'], axis=1)\n",
    "\n",
    "# save both testData and trainData for future use\n",
    "trainData.to_csv('./Dataset/trainingData', index=False)\n",
    "testData.to_csv('./Dataset/testingData', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and shuffle dataset\n",
    "testData = pd.read_csv('./Dataset/testingData').astype('float32')\n",
    "testData = testData.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudSample = testData[testData['Class'] == 1]\n",
    "nfraudSample = testData[testData['Class'] == 0].sample(800)\n",
    "\n",
    "sampleData = pd.concat([fraudSample, nfraudSample])\n",
    "dataY = sampleData[\"Class\"].values\n",
    "dataX = sampleData.drop([\"Class\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for TSNE visualization...\n",
    "def tsne_plot(x1, y1):\n",
    "    tsne = TSNE()\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth=1, alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth=1, alpha=0.8, label='Fraud')\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(dataX, dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's architecture\n",
    "\n",
    "# Losss function used...\n",
    "def negative_log_likelihood(x, rv_x):\n",
    "    return -tf.reduce_sum(rv_x.log_prob(x), axis=-1)\n",
    "\n",
    "def createModel():\n",
    "    input_shape = 29\n",
    "    latent_dim = 2\n",
    "\n",
    "    tfd = tfp.distributions\n",
    "\n",
    "    prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_dim))\n",
    "\n",
    "    encoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=input_shape, name='encoder_input'),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(8, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(latent_dim), activation=None),\n",
    "        tfp.layers.MultivariateNormalTriL(latent_dim, \n",
    "                           activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior)),\n",
    "    ], name='encoder')\n",
    "\n",
    "    decoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=[latent_dim]),\n",
    "        tf.keras.layers.Dense(8, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(20, activation=tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(tfp.layers.IndependentNormal.params_size(input_shape), activation=\"linear\"), \n",
    "        tfp.layers.IndependentNormal(input_shape),\n",
    "    ], name='decoder')\n",
    "\n",
    "    vaeModel = tf.keras.Model(inputs=encoder.inputs,\n",
    "                outputs=decoder(encoder.outputs[0]))\n",
    "    \n",
    "    vaeModel.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=negative_log_likelihood\n",
    "    )\n",
    "\n",
    "    return vaeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view model summary\n",
    "model = createModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model.load_weights(\"weight.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f22fa19263995c18b642ef2dc6c773af5620bdd311d33ec9bbed9059c9ea237"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
